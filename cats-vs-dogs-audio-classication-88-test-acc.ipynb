{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/conweezy/cats-vs-dogs-audio-classication-88-test-acc?scriptVersionId=115764207\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"<font size=\"5\">**1. Import Libraries**</font>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport librosa\nimport librosa.display\nfrom pydub import AudioSegment\nimport math\nimport os\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-12-31T15:59:24.848515Z","iopub.execute_input":"2022-12-31T15:59:24.849129Z","iopub.status.idle":"2022-12-31T15:59:35.275256Z","shell.execute_reply.started":"2022-12-31T15:59:24.848992Z","shell.execute_reply":"2022-12-31T15:59:35.273678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">**2. Create a class to load WAV files.**</font>","metadata":{}},{"cell_type":"code","source":"class Loader:\n  '''Loads the WAV files'''\n  def __init__(self, sample_rate, mono, duration):\n    self.sample_rate = sample_rate\n    self.mono = mono\n    self.duration = duration\n\n  def load(self, file_path):\n    signal = librosa.load(file_path,\n                       sr=self.sample_rate,\n                       mono=self.mono)[0]\n    return signal","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:00:28.396322Z","iopub.execute_input":"2022-12-31T16:00:28.397242Z","iopub.status.idle":"2022-12-31T16:00:28.406754Z","shell.execute_reply.started":"2022-12-31T16:00:28.397193Z","shell.execute_reply":"2022-12-31T16:00:28.404931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Test loader class on a sample cat audio'''\nSAMPLE_RATE = 22050\nDURATION = 5\nMONO = True\nFILE_PATH_CAT = '../input/audio-cats-and-dogs/cats_dogs/train/cat/cat_1.wav'\nloader = Loader(SAMPLE_RATE, MONO, DURATION)\nsignal_cat= loader.load(FILE_PATH_CAT)\n\nfrom IPython.display import Audio\n\nAudio(signal_cat, rate=SAMPLE_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:04:43.033754Z","iopub.execute_input":"2022-12-31T16:04:43.034263Z","iopub.status.idle":"2022-12-31T16:04:43.287968Z","shell.execute_reply.started":"2022-12-31T16:04:43.034223Z","shell.execute_reply":"2022-12-31T16:04:43.286387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FILE_PATH_DOG = '../input/audio-cats-and-dogs/cats_dogs/train/dog/dog_barking_1.wav'\nloader = Loader(SAMPLE_RATE, DURATION, MONO)\nsignal_dog = loader.load(FILE_PATH_DOG)\n\nfrom IPython.display import Audio\nsr=22050\n\n\nAudio(signal_dog, rate=sr)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:06:07.985645Z","iopub.execute_input":"2022-12-31T16:06:07.98628Z","iopub.status.idle":"2022-12-31T16:06:08.263462Z","shell.execute_reply.started":"2022-12-31T16:06:07.98622Z","shell.execute_reply":"2022-12-31T16:06:08.262444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display cat sample\nlibrosa.display.waveshow(signal_cat)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:06:53.996946Z","iopub.execute_input":"2022-12-31T16:06:53.997395Z","iopub.status.idle":"2022-12-31T16:06:54.38323Z","shell.execute_reply.started":"2022-12-31T16:06:53.997358Z","shell.execute_reply":"2022-12-31T16:06:54.382062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display dog sample\nlibrosa.display.waveshow(signal_dog)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:06:52.318008Z","iopub.execute_input":"2022-12-31T16:06:52.318458Z","iopub.status.idle":"2022-12-31T16:06:52.761295Z","shell.execute_reply.started":"2022-12-31T16:06:52.318421Z","shell.execute_reply":"2022-12-31T16:06:52.759795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">**2. Create helper classes.**</font>\n\nLooking at the 2 above samples, as well as other samples, we see the Time is longer than we need for this classification task. Audio samples tend to work better with shorter samples of uniform duration. Additionally, there is not a lot of data for either class. To help solve both these issues we can split all the current samples into 1 second samples. This creates more data, all of uniform length.\n\nTo improve upon this, it would also be possible to split the samples precisely on each cat meow or dog bark. For example, in the above dog Wavplot, you could split from 0-2 seconds, then about 3.5-5.\n\nMore helper classes are created below which convert the WAV to a spectrgoram, PAD any samples that end up being less than 1 second, then Normalize all the samples using MinMaxNormliaztion.","metadata":{}},{"cell_type":"code","source":"class SplitWavAudio():\n    '''This class splits the audio into uniform duration samples'''\n    def __init__(self, load_folder, save_folder, filename):\n        self.load_folder = load_folder\n        self.filename = filename\n        self.filepath = load_folder + '/' + filename\n        self.save_folder = save_folder\n        self.audio = AudioSegment.from_wav(self.filepath)\n    \n    def get_duration(self):\n        return self.audio.duration_seconds\n    \n    def single_split(self, from_sec, to_sec, split_filename):\n        t1 = from_sec * 1000\n        t2 = to_sec * 1000\n        split_audio = self.audio[t1:t2]\n        split_audio.export(self.save_folder + '/' + split_filename, format=\"wav\")\n        \n    def multiple_split(self, seconds_per_split):\n        total_seconds = math.ceil(self.get_duration())\n        for i in range(0, total_seconds, seconds_per_split):\n            split_fn = str(i) + '_' + self.filename\n            self.single_split(i, i+seconds_per_split, split_fn)\n        print('Done')","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:39:22.290015Z","iopub.execute_input":"2022-12-31T16:39:22.290527Z","iopub.status.idle":"2022-12-31T16:39:22.301843Z","shell.execute_reply.started":"2022-12-31T16:39:22.29048Z","shell.execute_reply":"2022-12-31T16:39:22.300581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class spectrogram_extractor:\n  '''Converts wav file into a spectrogram by applying STFT.'''   \n  def __init__(self, frame_size, hop_length):\n    self.frame_size = frame_size\n    self.hop_length = hop_length\n\n  def spec_extract(self, signal):\n    self.signal = signal\n    stft = librosa.stft(self.signal,\n                               hop_length=self.hop_length,\n                               n_fft=self.frame_size)\n    spectrogram = np.abs(stft)\n    return spectrogram","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:20:02.099729Z","iopub.execute_input":"2022-12-31T16:20:02.100231Z","iopub.status.idle":"2022-12-31T16:20:02.109192Z","shell.execute_reply.started":"2022-12-31T16:20:02.100194Z","shell.execute_reply":"2022-12-31T16:20:02.107375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a samples spectrgoram of cat audio\nFRAME_SIZE = 512\nHOP_LENGTH = 256\n\next = spectrogram_extractor(FRAME_SIZE, HOP_LENGTH)\nspec = ext.spec_extract(signal_cat)\n\nlibrosa.display.specshow(spec)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:20:36.10472Z","iopub.execute_input":"2022-12-31T16:20:36.10517Z","iopub.status.idle":"2022-12-31T16:20:36.535098Z","shell.execute_reply.started":"2022-12-31T16:20:36.105137Z","shell.execute_reply":"2022-12-31T16:20:36.533632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''The raw wav file durations are not interger values, so we end up with some samples that are less than 1 second. \nTo fix this, Right Padding is applied.'''\n\ndef pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0) -> np.ndarray:\n\n    pad_size = target_length - array.shape[axis]\n\n    if pad_size <= 0:\n        return array\n\n    npad = [(0, 0)] * array.ndim\n    npad[axis] = (0, pad_size)\n\n    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:23:27.922096Z","iopub.execute_input":"2022-12-31T16:23:27.922531Z","iopub.status.idle":"2022-12-31T16:23:27.931757Z","shell.execute_reply.started":"2022-12-31T16:23:27.9225Z","shell.execute_reply":"2022-12-31T16:23:27.929862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MinMaxNormaliser:\n    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n\n    def __init__(self, min_val, max_val):\n        self.min = min_val\n        self.max = max_val\n\n    def normalise(self, array):\n        norm_array = (array - array.min()) / (array.max() - array.min())\n        norm_array = norm_array * (self.max - self.min) + self.min\n        return norm_array\n","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:23:47.69934Z","iopub.execute_input":"2022-12-31T16:23:47.699752Z","iopub.status.idle":"2022-12-31T16:23:47.707153Z","shell.execute_reply.started":"2022-12-31T16:23:47.699722Z","shell.execute_reply":"2022-12-31T16:23:47.705952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(path):\n  for i in os.listdir(path):\n    file_path = os.path.join(path, i)\n    try:\n      signal = loader.load(file_path)\n      spectrogram = ext.spec_extract(signal)\n    except:\n        continue\n    spec_norm = min_max_normaliser.normalise(spectrogram)\n    spec_pad = pad_along_axis(spec_norm, 87, 1)\n    X_data.append(spec_pad)\n    if \"cat\" in file_path:\n      y_data.append(0)\n    else:\n      y_data.append(1)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:24:15.418952Z","iopub.execute_input":"2022-12-31T16:24:15.419422Z","iopub.status.idle":"2022-12-31T16:24:15.428187Z","shell.execute_reply.started":"2022-12-31T16:24:15.419388Z","shell.execute_reply":"2022-12-31T16:24:15.42644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">**3. Create the Training and Testing Datasets.**</font>\n\n","metadata":{}},{"cell_type":"code","source":"'''First run the function that splits the wav files into 1 second samples. \nI ran this on all Train and Test folders(need to run 4 times total) and saved the outputs in a new Data folder. \nI will create my own train/test split later'''\nfor f in os.listdir('../input/audio-cats-and-dogs/cats_dogs/test/test'):\n  split = SplitWavAudio('../input/audio-cats-and-dogs/cats_dogs/test/test', '/kaggle/working/Data', f)\n  split.multiple_split(1)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:40:27.089697Z","iopub.execute_input":"2022-12-31T16:40:27.090138Z","iopub.status.idle":"2022-12-31T16:40:27.27236Z","shell.execute_reply.started":"2022-12-31T16:40:27.090103Z","shell.execute_reply":"2022-12-31T16:40:27.271102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Create full dataset'''\nPATH = '/kaggle/working/Data'\n\nDURATION = 5\nMONO = True\nFRAME_SIZE = 512\nHOP_LENGTH = 256\n\nloader = Loader(SAMPLE_RATE, DURATION, MONO)\next = spectrogram_extractor(FRAME_SIZE, HOP_LENGTH)\nmin_max_normaliser = MinMaxNormaliser(0,1)\n\n\nX_data = []\ny_data = []\n\ncreate_dataset(PATH)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:43:08.013892Z","iopub.execute_input":"2022-12-31T16:43:08.015855Z","iopub.status.idle":"2022-12-31T16:43:54.799999Z","shell.execute_reply.started":"2022-12-31T16:43:08.01578Z","shell.execute_reply":"2022-12-31T16:43:54.798806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Make sure all the files got added to the dataset.\nThe cats are labeled as 0 in the y_data and dogs 1\nPrinting the number of Non-Zeros shows that there is still much more cat data than dogs.\nTo improve overall performance, the model could be adjusted to account for this uneven amount of data'''\nX_data = np.array(X_data)\ny_data = np.array(y_data)\n\nprint(X_data.shape)\nprint(y_data.shape)\nnp.count_nonzero(y_data)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:45:13.451586Z","iopub.execute_input":"2022-12-31T16:45:13.452023Z","iopub.status.idle":"2022-12-31T16:45:13.657251Z","shell.execute_reply.started":"2022-12-31T16:45:13.451992Z","shell.execute_reply":"2022-12-31T16:45:13.65568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Use Sklearn to create train/test split and shuffle the data'''\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_data, y_data, test_size=.2, train_size=.8, shuffle=True)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:45:52.519015Z","iopub.execute_input":"2022-12-31T16:45:52.520582Z","iopub.status.idle":"2022-12-31T16:45:52.646358Z","shell.execute_reply.started":"2022-12-31T16:45:52.520505Z","shell.execute_reply":"2022-12-31T16:45:52.64489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Convolutional model expects a channel dimension. In this case the audio is Mono, so there is just 1 channel'''\nX_train = np.reshape(X_train, (-1, 257, 87, 1))\nX_test = np.reshape(X_test, (-1, 257, 87, 1))\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:58:08.958646Z","iopub.execute_input":"2022-12-31T16:58:08.959095Z","iopub.status.idle":"2022-12-31T16:58:08.966304Z","shell.execute_reply.started":"2022-12-31T16:58:08.959051Z","shell.execute_reply":"2022-12-31T16:58:08.965397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Finally, we convert the numpy arrays into Tensorflow dataset objects'''\n# Create Tensorflow Dataset Objects\n\nBATCH_SIZE = 15\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=False)\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\ntest_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\ntrain_dataset = train_dataset.shuffle(buffer_size=256)\ntest_dataset = test_dataset.shuffle(buffer_size=256)\nprint(train_dataset)\nprint(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:58:13.402085Z","iopub.execute_input":"2022-12-31T16:58:13.403279Z","iopub.status.idle":"2022-12-31T16:58:13.443607Z","shell.execute_reply.started":"2022-12-31T16:58:13.403229Z","shell.execute_reply":"2022-12-31T16:58:13.442208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">**4. Create the Model.**</font>\n\nThe model used is a 5 layer convolutional Neural Network. Other model architectures that are used for time series such as LSTM might provide good results as well.","metadata":{}},{"cell_type":"code","source":"# Create Model\ncnn = tf.keras.models.Sequential([\n    \n    # The first convolution\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(257, 87, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # The second convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    # The fourth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    # The fifth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    #tf.keras.layers.MaxPooling2D(2,2),\n\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid')                                \n                                    ])\n\nprint(cnn.summary())","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:58:17.64371Z","iopub.execute_input":"2022-12-31T16:58:17.644231Z","iopub.status.idle":"2022-12-31T16:58:17.761562Z","shell.execute_reply.started":"2022-12-31T16:58:17.644191Z","shell.execute_reply":"2022-12-31T16:58:17.760002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set training parameters and number of epochs\ncnn.compile(loss='binary_crossentropy',\n              optimizer=Adam(learning_rate=1e-4),\n              metrics=['accuracy'])\n\nEPOCHS = 50","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:58:21.637385Z","iopub.execute_input":"2022-12-31T16:58:21.637859Z","iopub.status.idle":"2022-12-31T16:58:21.653745Z","shell.execute_reply.started":"2022-12-31T16:58:21.637825Z","shell.execute_reply":"2022-12-31T16:58:21.652182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">**5. Train and Evaluate the Model.**</font>","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = cnn.fit(\n      train_dataset,\n      epochs=EPOCHS,\n      verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:58:24.611519Z","iopub.execute_input":"2022-12-31T16:58:24.611965Z","iopub.status.idle":"2022-12-31T17:05:43.83321Z","shell.execute_reply.started":"2022-12-31T16:58:24.611933Z","shell.execute_reply":"2022-12-31T17:05:43.832279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validate = cnn.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T17:06:36.753065Z","iopub.execute_input":"2022-12-31T17:06:36.753548Z","iopub.status.idle":"2022-12-31T17:06:37.444165Z","shell.execute_reply.started":"2022-12-31T17:06:36.753511Z","shell.execute_reply":"2022-12-31T17:06:37.443007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}